{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27b3f3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip ./food11.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29a02d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83037202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(PATH,LABEL):\n",
    "    image_dir = sorted(os.listdir(PATH))\n",
    "    x = np.zeros((len(image_dir),128,128,3),dtype = np.uint8)\n",
    "    y = np.zeros((len(image_dir)),dtype = np.int64)\n",
    "    for i,FILE in enumerate(image_dir):\n",
    "        img = cv2.imread(os.path.join(PATH,FILE))\n",
    "        x[i,:,:] = cv2.resize(img,(128,128))\n",
    "        if LABEL:\n",
    "            y[i] = int(FILE.split('_')[0])\n",
    "        if i % 1000 == 0:\n",
    "            print(f'Read complete: {i}/{len(image_dir)}')\n",
    "    if LABEL:\n",
    "        return x,y\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "533706a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read complete: 0/9866\n",
      "Read complete: 1000/9866\n",
      "Read complete: 2000/9866\n",
      "Read complete: 3000/9866\n",
      "Read complete: 4000/9866\n",
      "Read complete: 5000/9866\n",
      "Read complete: 6000/9866\n",
      "Read complete: 7000/9866\n",
      "Read complete: 8000/9866\n",
      "Read complete: 9000/9866\n",
      "Size of training set = 9866\n",
      "%2.2f sec(s)\n",
      "Read complete: 0/3430\n",
      "Read complete: 1000/3430\n",
      "Read complete: 2000/3430\n",
      "Read complete: 3000/3430\n",
      "size of validation set = 3430\n",
      "Read complete: 0/3347\n",
      "Read complete: 1000/3347\n",
      "Read complete: 2000/3347\n",
      "Read complete: 3000/3347\n",
      "Size of testing set = 3347\n"
     ]
    }
   ],
   "source": [
    "time_1 = time.time()\n",
    "workspace_dir = './food-11/'\n",
    "train_x,train_y = readfile(os.path.join(workspace_dir,'training'),True)\n",
    "time_2 = time.time()\n",
    "print(f'Size of training set = {len(train_x)}')\n",
    "print('%2.2f sec(s)'.format(time_2-time_1))\n",
    "val_x,val_y = readfile(os.path.join(workspace_dir,'validation'),True)\n",
    "print(f'size of validation set = {len(val_x)}')\n",
    "test_x = readfile(os.path.join(workspace_dir,'testing'),False)\n",
    "print(f'Size of testing set = {len(test_x)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ce184ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9525ed7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = transforms.Compose([transforms.ToPILImage(),transforms.AutoAugment(),transforms.ToTensor()])\n",
    "transforms_test = transforms.Compose([transforms.ToPILImage(),transforms.ToTensor()])\n",
    "class ImgDataSetter(Dataset):\n",
    "    def __init__(self,x,y = None,transform = None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        if y is not None:\n",
    "            self.y = y\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self,index):\n",
    "        X = self.x[index]\n",
    "        if self.transform is not None:\n",
    "            X = self.transform(X)\n",
    "        if self.y is not None:\n",
    "            Y = self.y[index]\n",
    "            return X,Y\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19bc0b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_set = ImgDataSetter(train_x,train_y,transforms_train)\n",
    "val_set = ImgDataSetter(val_x,val_y,transforms_test)\n",
    "trn_loader = DataLoader(train_set,batch_size = batch_size,shuffle = True)\n",
    "val_loader = DataLoader(val_set,batch_size = batch_size,shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cbc667f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class simpleClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(simpleClassifier,self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3,64,3,1,1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2,2,0),\n",
    "        \n",
    "            nn.Conv2d(64,128,3,1,1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2,2,0),\n",
    "        \n",
    "            nn.Conv2d(128,256,3,1,1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2,2,0),\n",
    "        \n",
    "            nn.Conv2d(256,512,3,1,1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2,2,0),\n",
    "        \n",
    "            nn.Conv2d(512,512,3,1,1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool2d(2,2,0)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512*4*4,1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(1024,512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512,11)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        out = self.cnn(x)\n",
    "        out = out.view(out.size()[0],-1) # flatten\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d95c6c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[001/015] 181.9769 sec(s),[Train]acc|loss|time: 0.245490|0.066584|165.5304 sec(s),[Val]acc|loss|time: 0.363265|0.057631|16.4465 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[002/015] 179.3160 sec(s),[Train]acc|loss|time: 0.350598|0.058947|163.5103 sec(s),[Val]acc|loss|time: 0.410787|0.053677|15.8056 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[003/015] 177.3424 sec(s),[Train]acc|loss|time: 0.412629|0.053774|161.0851 sec(s),[Val]acc|loss|time: 0.488047|0.046793|16.2573 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[004/015] 173.6710 sec(s),[Train]acc|loss|time: 0.443138|0.050350|157.5406 sec(s),[Val]acc|loss|time: 0.462099|0.050136|16.1305 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[005/015] 179.6485 sec(s),[Train]acc|loss|time: 0.477397|0.047917|164.1577 sec(s),[Val]acc|loss|time: 0.481050|0.046347|15.4908 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[006/015] 177.8526 sec(s),[Train]acc|loss|time: 0.497567|0.046142|161.3711 sec(s),[Val]acc|loss|time: 0.520991|0.043219|16.4815 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[007/015] 174.8385 sec(s),[Train]acc|loss|time: 0.518042|0.044205|159.2216 sec(s),[Val]acc|loss|time: 0.550729|0.041093|15.6169 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[008/015] 177.1391 sec(s),[Train]acc|loss|time: 0.539023|0.042753|161.2264 sec(s),[Val]acc|loss|time: 0.504373|0.044288|15.9127 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[009/015] 179.6113 sec(s),[Train]acc|loss|time: 0.560207|0.040939|163.2445 sec(s),[Val]acc|loss|time: 0.545481|0.042180|16.3668 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[010/015] 177.5561 sec(s),[Train]acc|loss|time: 0.573181|0.039714|159.7492 sec(s),[Val]acc|loss|time: 0.550146|0.042914|17.8069 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[011/015] 180.1010 sec(s),[Train]acc|loss|time: 0.593250|0.038457|164.7913 sec(s),[Val]acc|loss|time: 0.549271|0.042838|15.3097 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[012/015] 176.6148 sec(s),[Train]acc|loss|time: 0.600041|0.037441|161.1355 sec(s),[Val]acc|loss|time: 0.562099|0.039679|15.4792 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[013/015] 173.3164 sec(s),[Train]acc|loss|time: 0.617474|0.035914|156.3781 sec(s),[Val]acc|loss|time: 0.596501|0.037901|16.9383 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[014/015] 178.3509 sec(s),[Train]acc|loss|time: 0.635516|0.034031|161.2273 sec(s),[Val]acc|loss|time: 0.540525|0.042849|17.1236 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[015/015] 180.0958 sec(s),[Train]acc|loss|time: 0.650618|0.032952|164.1794 sec(s),[Val]acc|loss|time: 0.537026|0.042819|15.9164 sec(s)\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 2e-5\n",
    "epoch_num = 15\n",
    "val_acc_history = []\n",
    "val_loss_history = []\n",
    "train_acc_history = []\n",
    "train_loss_history = []\n",
    "\n",
    "model = simpleClassifier().cuda()\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr = learning_rate)\n",
    "num_epoch = epoch_num\n",
    "\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    epoch_start_time = time.time()\n",
    "    epoch_train_time = time.time()\n",
    "    val_acc = 0.0\n",
    "    val_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    for batch_id,DATA in enumerate(trn_loader):\n",
    "        optimizer.zero_grad()\n",
    "        train_pred = model(DATA[0].cuda())\n",
    "        batch_loss = loss(train_pred,DATA[1].cuda())\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        train_acc += np.sum(np.argmax(train_pred.cpu().data.numpy(),axis = 1) == DATA[1].numpy())\n",
    "        train_loss += batch_loss.item()\n",
    "        train_acc_history.append(train_acc)\n",
    "        train_loss_history.append(train_loss)\n",
    "        if batch_id % 100 == 0:\n",
    "            print(f'training: batch#{batch_id}')\n",
    "\n",
    "    epoch_eval_time = time.time()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i,DATA in enumerate(val_loader):\n",
    "            val_pred = model(DATA[0].cuda())\n",
    "            batch_loss = loss(val_pred,DATA[1].cuda())\n",
    "            val_acc += np.sum(np.argmax(val_pred.cpu().data.numpy(),axis = 1) == DATA[1].numpy())\n",
    "            val_loss += batch_loss.item()\n",
    "            val_acc_history.append(val_acc)\n",
    "            val_loss_history.append(val_loss)\n",
    "            if batch_id % 100 == 0:\n",
    "                print(f'validating: batch{batch_id}')\n",
    "    print('[%03d/%03d] %2.4f sec(s),[Train]acc|loss|time: %3.6f|%3.6f|%2.4f sec(s),[Val]acc|loss|time: %3.6f|%3.6f|%2.4f sec(s)' % (epoch+1,epoch_num,time.time()-epoch_start_time,train_acc/train_set.__len__(),train_loss/train_set.__len__(),epoch_eval_time-epoch_train_time,val_acc/val_set.__len__(),val_loss/val_set.__len__(),time.time()-epoch_eval_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "131d86e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 128, 128]           1,792\n",
      "       BatchNorm2d-2         [-1, 64, 128, 128]             128\n",
      "         LeakyReLU-3         [-1, 64, 128, 128]               0\n",
      "         MaxPool2d-4           [-1, 64, 64, 64]               0\n",
      "            Conv2d-5          [-1, 128, 64, 64]          73,856\n",
      "       BatchNorm2d-6          [-1, 128, 64, 64]             256\n",
      "         LeakyReLU-7          [-1, 128, 64, 64]               0\n",
      "         MaxPool2d-8          [-1, 128, 32, 32]               0\n",
      "            Conv2d-9          [-1, 256, 32, 32]         295,168\n",
      "      BatchNorm2d-10          [-1, 256, 32, 32]             512\n",
      "        LeakyReLU-11          [-1, 256, 32, 32]               0\n",
      "        MaxPool2d-12          [-1, 256, 16, 16]               0\n",
      "           Conv2d-13          [-1, 512, 16, 16]       1,180,160\n",
      "      BatchNorm2d-14          [-1, 512, 16, 16]           1,024\n",
      "        LeakyReLU-15          [-1, 512, 16, 16]               0\n",
      "        MaxPool2d-16            [-1, 512, 8, 8]               0\n",
      "           Conv2d-17            [-1, 512, 8, 8]       2,359,808\n",
      "      BatchNorm2d-18            [-1, 512, 8, 8]           1,024\n",
      "        LeakyReLU-19            [-1, 512, 8, 8]               0\n",
      "        MaxPool2d-20            [-1, 512, 4, 4]               0\n",
      "           Linear-21                 [-1, 1024]       8,389,632\n",
      "        LeakyReLU-22                 [-1, 1024]               0\n",
      "           Linear-23                  [-1, 512]         524,800\n",
      "        LeakyReLU-24                  [-1, 512]               0\n",
      "           Linear-25                   [-1, 11]           5,643\n",
      "================================================================\n",
      "Total params: 12,833,803\n",
      "Trainable params: 12,833,803\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 49.59\n",
      "Params size (MB): 48.96\n",
      "Estimated Total Size (MB): 98.73\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = simpleClassifier().cuda()\n",
    "from torchsummary import summary\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    " \n",
    "summary(model,(3,128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ee7821db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3f9e5560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x22354ef52b0>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,ax = plt.subplots()\n",
    "x = np.linspace(1,epoch_num,epoch_num)\n",
    "x = x.transpose()\n",
    "val_acc_history = np.array(val_acc_history) / val_set.__len__()\n",
    "val_loss_history = np.array(val_loss_history) / val_set.__len__()\n",
    "train_acc_history = np.array(train_acc_history) / train_set.__len__()\n",
    "train_loss_history = np.array(train_loss_history) / train_set.__len__()\n",
    "ax.plot(x,val_acc_history[-epoch_num:],label = 'val_acc')\n",
    "ax.plot(x,val_loss_history[-epoch_num:],label = 'val_loss')\n",
    "ax.plot(x,train_acc_history[-epoch_num:],label = 'train_acc')\n",
    "ax.plot(x,train_loss_history[-epoch_num:],label = 'train_loss')\n",
    "ax.grid()\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ac1495d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual_Block(nn.Module):\n",
    "    def __init__(self,i_channel,o_channel,stride = 1, down_sample = None):\n",
    "        super(Residual_Block,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = i_channel,out_channels = i_channel//4,kernel_size = 1,stride = 1,padding = 0)\n",
    "        self.bn1 = nn.BatchNorm2d(i_channel//4)\n",
    "        self.relu = nn.LeakyReLU(inplace = True)\n",
    "        self.conv2 = nn.Conv2d(in_channels = i_channel//4,out_channels = i_channel//4,kernel_size = 3,stride = 1,padding = 1)\n",
    "        self.bn2 = nn.BatchNorm2d(i_channel//4)\n",
    "        self.conv3 = nn.Conv2d(in_channels = i_channel//4,out_channels = o_channel,kernel_size = 1,stride = 1,padding = 0)\n",
    "        self.bn3 = nn.BatchNorm2d(o_channel)\n",
    "        self.down_sample = down_sample\n",
    "    \n",
    "    def forward(self,x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        if self.down_sample:\n",
    "            residual = self.down_sample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c6222de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual_Block(nn.Module):\n",
    "    def __init__(self,i_channel,o_channel,stride = 1, down_sample = None):\n",
    "        super(Residual_Block,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = i_channel,out_channels = o_channel,kernel_size = 1,stride = stride,padding = 0)\n",
    "        self.bn1 = nn.BatchNorm2d(o_channel)\n",
    "        self.relu = nn.LeakyReLU(inplace = True)\n",
    "        self.conv2 = nn.Conv2d(in_channels = o_channel,out_channels = o_channel,kernel_size = 3,stride = 1,padding = 1)\n",
    "        self.bn2 = nn.BatchNorm2d(o_channel)\n",
    "        self.down_sample = down_sample\n",
    "    \n",
    "    def forward(self,x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        if self.down_sample:\n",
    "            residual = self.down_sample(x)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63d9bd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self,block,layers,num_classes = 11):\n",
    "        super(ResNet,self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels = 3,out_channels = 16,kernel_size = 3,stride = 1,padding = 1,bias = False)\n",
    "        self.in_channels = 16\n",
    "        self.bn = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.LeakyReLU(inplace = True)\n",
    "        self.layer1 = self.make_layer(block,16,layers[0])\n",
    "        self.layer2 = self.make_layer(block,32,layers[1],2)\n",
    "        self.layer3 = self.make_layer(block,64,layers[2],2)\n",
    "        self.avg_pool = nn.AvgPool2d(8)\n",
    "        self.fc = nn.Linear(1024,num_classes)\n",
    "        self.dropout = nn.Dropout(p = 0.5)\n",
    "    \n",
    "    def make_layer(self,block,out_channels,blocks,stride = 1):\n",
    "        down_sample = None\n",
    "        if (stride != 1) or (self.in_channels != out_channels):\n",
    "            down_sample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels,out_channels,kernel_size = 3,stride = stride,padding = 1,bias = False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels,out_channels,stride,down_sample))\n",
    "        self.in_channels = out_channels\n",
    "        for i in range(blocks-1):\n",
    "            layers.append(block(out_channels,out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.avg_pool(out)\n",
    "        out = self.dropout(out)\n",
    "        out = out.view(out.size()[0],-1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "def update_lr(optimizer,lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6aca8100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 128, 128]             432\n",
      "       BatchNorm2d-2         [-1, 16, 128, 128]              32\n",
      "         LeakyReLU-3         [-1, 16, 128, 128]               0\n",
      "            Conv2d-4         [-1, 16, 128, 128]             272\n",
      "       BatchNorm2d-5         [-1, 16, 128, 128]              32\n",
      "         LeakyReLU-6         [-1, 16, 128, 128]               0\n",
      "            Conv2d-7         [-1, 16, 128, 128]           2,320\n",
      "       BatchNorm2d-8         [-1, 16, 128, 128]              32\n",
      "         LeakyReLU-9         [-1, 16, 128, 128]               0\n",
      "   Residual_Block-10         [-1, 16, 128, 128]               0\n",
      "           Conv2d-11         [-1, 16, 128, 128]             272\n",
      "      BatchNorm2d-12         [-1, 16, 128, 128]              32\n",
      "        LeakyReLU-13         [-1, 16, 128, 128]               0\n",
      "           Conv2d-14         [-1, 16, 128, 128]           2,320\n",
      "      BatchNorm2d-15         [-1, 16, 128, 128]              32\n",
      "        LeakyReLU-16         [-1, 16, 128, 128]               0\n",
      "   Residual_Block-17         [-1, 16, 128, 128]               0\n",
      "           Conv2d-18         [-1, 16, 128, 128]             272\n",
      "      BatchNorm2d-19         [-1, 16, 128, 128]              32\n",
      "        LeakyReLU-20         [-1, 16, 128, 128]               0\n",
      "           Conv2d-21         [-1, 16, 128, 128]           2,320\n",
      "      BatchNorm2d-22         [-1, 16, 128, 128]              32\n",
      "        LeakyReLU-23         [-1, 16, 128, 128]               0\n",
      "   Residual_Block-24         [-1, 16, 128, 128]               0\n",
      "           Conv2d-25         [-1, 16, 128, 128]             272\n",
      "      BatchNorm2d-26         [-1, 16, 128, 128]              32\n",
      "        LeakyReLU-27         [-1, 16, 128, 128]               0\n",
      "           Conv2d-28         [-1, 16, 128, 128]           2,320\n",
      "      BatchNorm2d-29         [-1, 16, 128, 128]              32\n",
      "        LeakyReLU-30         [-1, 16, 128, 128]               0\n",
      "   Residual_Block-31         [-1, 16, 128, 128]               0\n",
      "           Conv2d-32           [-1, 32, 64, 64]             544\n",
      "      BatchNorm2d-33           [-1, 32, 64, 64]              64\n",
      "        LeakyReLU-34           [-1, 32, 64, 64]               0\n",
      "           Conv2d-35           [-1, 32, 64, 64]           9,248\n",
      "      BatchNorm2d-36           [-1, 32, 64, 64]              64\n",
      "           Conv2d-37           [-1, 32, 64, 64]           4,608\n",
      "      BatchNorm2d-38           [-1, 32, 64, 64]              64\n",
      "        LeakyReLU-39           [-1, 32, 64, 64]               0\n",
      "   Residual_Block-40           [-1, 32, 64, 64]               0\n",
      "           Conv2d-41           [-1, 32, 64, 64]           1,056\n",
      "      BatchNorm2d-42           [-1, 32, 64, 64]              64\n",
      "        LeakyReLU-43           [-1, 32, 64, 64]               0\n",
      "           Conv2d-44           [-1, 32, 64, 64]           9,248\n",
      "      BatchNorm2d-45           [-1, 32, 64, 64]              64\n",
      "        LeakyReLU-46           [-1, 32, 64, 64]               0\n",
      "   Residual_Block-47           [-1, 32, 64, 64]               0\n",
      "           Conv2d-48           [-1, 32, 64, 64]           1,056\n",
      "      BatchNorm2d-49           [-1, 32, 64, 64]              64\n",
      "        LeakyReLU-50           [-1, 32, 64, 64]               0\n",
      "           Conv2d-51           [-1, 32, 64, 64]           9,248\n",
      "      BatchNorm2d-52           [-1, 32, 64, 64]              64\n",
      "        LeakyReLU-53           [-1, 32, 64, 64]               0\n",
      "   Residual_Block-54           [-1, 32, 64, 64]               0\n",
      "           Conv2d-55           [-1, 32, 64, 64]           1,056\n",
      "      BatchNorm2d-56           [-1, 32, 64, 64]              64\n",
      "        LeakyReLU-57           [-1, 32, 64, 64]               0\n",
      "           Conv2d-58           [-1, 32, 64, 64]           9,248\n",
      "      BatchNorm2d-59           [-1, 32, 64, 64]              64\n",
      "        LeakyReLU-60           [-1, 32, 64, 64]               0\n",
      "   Residual_Block-61           [-1, 32, 64, 64]               0\n",
      "           Conv2d-62           [-1, 64, 32, 32]           2,112\n",
      "      BatchNorm2d-63           [-1, 64, 32, 32]             128\n",
      "        LeakyReLU-64           [-1, 64, 32, 32]               0\n",
      "           Conv2d-65           [-1, 64, 32, 32]          36,928\n",
      "      BatchNorm2d-66           [-1, 64, 32, 32]             128\n",
      "           Conv2d-67           [-1, 64, 32, 32]          18,432\n",
      "      BatchNorm2d-68           [-1, 64, 32, 32]             128\n",
      "        LeakyReLU-69           [-1, 64, 32, 32]               0\n",
      "   Residual_Block-70           [-1, 64, 32, 32]               0\n",
      "           Conv2d-71           [-1, 64, 32, 32]           4,160\n",
      "      BatchNorm2d-72           [-1, 64, 32, 32]             128\n",
      "        LeakyReLU-73           [-1, 64, 32, 32]               0\n",
      "           Conv2d-74           [-1, 64, 32, 32]          36,928\n",
      "      BatchNorm2d-75           [-1, 64, 32, 32]             128\n",
      "        LeakyReLU-76           [-1, 64, 32, 32]               0\n",
      "   Residual_Block-77           [-1, 64, 32, 32]               0\n",
      "           Conv2d-78           [-1, 64, 32, 32]           4,160\n",
      "      BatchNorm2d-79           [-1, 64, 32, 32]             128\n",
      "        LeakyReLU-80           [-1, 64, 32, 32]               0\n",
      "           Conv2d-81           [-1, 64, 32, 32]          36,928\n",
      "      BatchNorm2d-82           [-1, 64, 32, 32]             128\n",
      "        LeakyReLU-83           [-1, 64, 32, 32]               0\n",
      "   Residual_Block-84           [-1, 64, 32, 32]               0\n",
      "           Conv2d-85           [-1, 64, 32, 32]           4,160\n",
      "      BatchNorm2d-86           [-1, 64, 32, 32]             128\n",
      "        LeakyReLU-87           [-1, 64, 32, 32]               0\n",
      "           Conv2d-88           [-1, 64, 32, 32]          36,928\n",
      "      BatchNorm2d-89           [-1, 64, 32, 32]             128\n",
      "        LeakyReLU-90           [-1, 64, 32, 32]               0\n",
      "   Residual_Block-91           [-1, 64, 32, 32]               0\n",
      "        AvgPool2d-92             [-1, 64, 4, 4]               0\n",
      "          Dropout-93             [-1, 64, 4, 4]               0\n",
      "           Linear-94                   [-1, 11]          11,275\n",
      "================================================================\n",
      "Total params: 250,139\n",
      "Trainable params: 250,139\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 107.02\n",
      "Params size (MB): 0.95\n",
      "Estimated Total Size (MB): 108.16\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "train_set = ImgDataSetter(train_x,train_y,transforms_train)\n",
    "val_set = ImgDataSetter(val_x,val_y,transforms_test)\n",
    "trn_loader = DataLoader(train_set,batch_size = batch_size,shuffle = True)\n",
    "val_loader = DataLoader(val_set,batch_size = batch_size,shuffle = False)\n",
    "\n",
    "import random\n",
    "random.seed(2)\n",
    "epoch_num = 100\n",
    "learning_rate = 1e-3\n",
    "model = ResNet(Residual_Block,[4,4,4,4]).cuda()\n",
    "\n",
    "from torchsummary import summary\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    " \n",
    "summary(model,(3,128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a93fa5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[001/100] 261.9524 sec(s),[Train]acc|loss|time: 0.196027|0.071355|237.0070 sec(s),[Val]acc|loss|time: 0.293003|0.063610|24.9453 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[002/100] 262.1641 sec(s),[Train]acc|loss|time: 0.250557|0.066326|237.0632 sec(s),[Val]acc|loss|time: 0.339650|0.058968|25.1009 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[003/100] 259.9830 sec(s),[Train]acc|loss|time: 0.285526|0.063675|234.4951 sec(s),[Val]acc|loss|time: 0.370845|0.056319|25.4879 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[004/100] 254.7451 sec(s),[Train]acc|loss|time: 0.311879|0.061709|229.2183 sec(s),[Val]acc|loss|time: 0.394169|0.054743|25.5268 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[005/100] 259.6132 sec(s),[Train]acc|loss|time: 0.332658|0.059791|234.0944 sec(s),[Val]acc|loss|time: 0.403499|0.053196|25.5188 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[006/100] 248.8516 sec(s),[Train]acc|loss|time: 0.347557|0.058126|225.3355 sec(s),[Val]acc|loss|time: 0.440233|0.050838|23.5161 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[007/100] 250.1958 sec(s),[Train]acc|loss|time: 0.360835|0.056840|225.0041 sec(s),[Val]acc|loss|time: 0.431778|0.052072|25.1917 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[008/100] 251.7047 sec(s),[Train]acc|loss|time: 0.378776|0.055487|225.9017 sec(s),[Val]acc|loss|time: 0.456560|0.049218|25.8030 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[009/100] 243.5408 sec(s),[Train]acc|loss|time: 0.400466|0.054290|219.1051 sec(s),[Val]acc|loss|time: 0.440816|0.051012|24.4357 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[010/100] 251.9984 sec(s),[Train]acc|loss|time: 0.413237|0.053160|227.5877 sec(s),[Val]acc|loss|time: 0.487172|0.046818|24.4108 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[011/100] 247.5299 sec(s),[Train]acc|loss|time: 0.417393|0.052387|223.0763 sec(s),[Val]acc|loss|time: 0.506414|0.045924|24.4536 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[012/100] 254.1084 sec(s),[Train]acc|loss|time: 0.431989|0.051288|229.3187 sec(s),[Val]acc|loss|time: 0.509329|0.045258|24.7897 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[013/100] 253.0698 sec(s),[Train]acc|loss|time: 0.436144|0.050647|227.9191 sec(s),[Val]acc|loss|time: 0.484257|0.048099|25.1507 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[014/100] 255.3918 sec(s),[Train]acc|loss|time: 0.453679|0.049472|231.2803 sec(s),[Val]acc|loss|time: 0.507872|0.044861|24.1115 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[015/100] 251.5694 sec(s),[Train]acc|loss|time: 0.460470|0.048989|225.8492 sec(s),[Val]acc|loss|time: 0.523324|0.044163|25.7203 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[016/100] 253.2402 sec(s),[Train]acc|loss|time: 0.467869|0.047861|227.8141 sec(s),[Val]acc|loss|time: 0.542566|0.041924|25.4260 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[017/100] 249.9295 sec(s),[Train]acc|loss|time: 0.473241|0.047631|225.3143 sec(s),[Val]acc|loss|time: 0.497668|0.046457|24.6152 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[018/100] 249.9519 sec(s),[Train]acc|loss|time: 0.487026|0.046532|225.3248 sec(s),[Val]acc|loss|time: 0.521866|0.043888|24.6272 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[019/100] 253.9043 sec(s),[Train]acc|loss|time: 0.492195|0.045756|228.6029 sec(s),[Val]acc|loss|time: 0.528863|0.043538|25.3014 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[020/100] 254.8115 sec(s),[Train]acc|loss|time: 0.504865|0.045062|229.3935 sec(s),[Val]acc|loss|time: 0.527405|0.043393|25.4181 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[021/100] 256.4136 sec(s),[Train]acc|loss|time: 0.517231|0.044456|230.9706 sec(s),[Val]acc|loss|time: 0.565306|0.040199|25.4430 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[022/100] 258.4089 sec(s),[Train]acc|loss|time: 0.525846|0.043532|232.1132 sec(s),[Val]acc|loss|time: 0.587464|0.038428|26.2957 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[023/100] 260.9807 sec(s),[Train]acc|loss|time: 0.539023|0.042951|233.9011 sec(s),[Val]acc|loss|time: 0.561516|0.040857|27.0796 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[024/100] 251.8853 sec(s),[Train]acc|loss|time: 0.534969|0.042481|227.1774 sec(s),[Val]acc|loss|time: 0.566764|0.039842|24.7080 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[025/100] 252.2610 sec(s),[Train]acc|loss|time: 0.543179|0.042124|227.4015 sec(s),[Val]acc|loss|time: 0.577259|0.038253|24.8595 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[026/100] 256.0450 sec(s),[Train]acc|loss|time: 0.549564|0.041344|230.6189 sec(s),[Val]acc|loss|time: 0.574344|0.039400|25.4260 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[027/100] 260.1825 sec(s),[Train]acc|loss|time: 0.554835|0.040971|232.4227 sec(s),[Val]acc|loss|time: 0.609038|0.037129|27.7598 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[028/100] 252.1539 sec(s),[Train]acc|loss|time: 0.551591|0.040508|227.4060 sec(s),[Val]acc|loss|time: 0.602915|0.036273|24.7479 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[029/100] 259.9686 sec(s),[Train]acc|loss|time: 0.564768|0.040184|234.6922 sec(s),[Val]acc|loss|time: 0.613411|0.036418|25.2764 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[030/100] 254.7007 sec(s),[Train]acc|loss|time: 0.566998|0.039705|230.1453 sec(s),[Val]acc|loss|time: 0.625364|0.034938|24.5554 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[031/100] 248.0892 sec(s),[Train]acc|loss|time: 0.576019|0.039157|222.4976 sec(s),[Val]acc|loss|time: 0.621574|0.037256|25.5916 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[032/100] 257.9687 sec(s),[Train]acc|loss|time: 0.572268|0.038725|232.9077 sec(s),[Val]acc|loss|time: 0.635277|0.034393|25.0610 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[033/100] 251.9619 sec(s),[Train]acc|loss|time: 0.586256|0.038202|223.7264 sec(s),[Val]acc|loss|time: 0.588047|0.038896|28.2355 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[034/100] 257.2570 sec(s),[Train]acc|loss|time: 0.590614|0.037913|232.2219 sec(s),[Val]acc|loss|time: 0.587464|0.040196|25.0351 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[035/100] 255.1014 sec(s),[Train]acc|loss|time: 0.594770|0.036900|229.5866 sec(s),[Val]acc|loss|time: 0.627697|0.035556|25.5148 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[036/100] 255.8193 sec(s),[Train]acc|loss|time: 0.601561|0.036520|230.3304 sec(s),[Val]acc|loss|time: 0.590962|0.039666|25.4889 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[037/100] 257.3964 sec(s),[Train]acc|loss|time: 0.598723|0.037001|230.7476 sec(s),[Val]acc|loss|time: 0.620991|0.035752|26.6488 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[038/100] 256.1287 sec(s),[Train]acc|loss|time: 0.610785|0.036074|230.1093 sec(s),[Val]acc|loss|time: 0.651020|0.032861|26.0195 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[039/100] 256.8342 sec(s),[Train]acc|loss|time: 0.608859|0.035683|231.3613 sec(s),[Val]acc|loss|time: 0.634111|0.035413|25.4729 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[040/100] 257.5633 sec(s),[Train]acc|loss|time: 0.617981|0.035124|232.9252 sec(s),[Val]acc|loss|time: 0.632070|0.034308|24.6382 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[041/100] 266.3463 sec(s),[Train]acc|loss|time: 0.619603|0.034892|239.0910 sec(s),[Val]acc|loss|time: 0.620700|0.036479|27.2553 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[042/100] 263.8194 sec(s),[Train]acc|loss|time: 0.631158|0.034330|237.9785 sec(s),[Val]acc|loss|time: 0.655977|0.033394|25.8409 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[043/100] 263.4306 sec(s),[Train]acc|loss|time: 0.623454|0.034550|237.1398 sec(s),[Val]acc|loss|time: 0.623615|0.034988|26.2907 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[044/100] 263.3976 sec(s),[Train]acc|loss|time: 0.635415|0.033927|236.6720 sec(s),[Val]acc|loss|time: 0.636443|0.033892|26.7256 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[045/100] 257.3025 sec(s),[Train]acc|loss|time: 0.639773|0.033425|232.1139 sec(s),[Val]acc|loss|time: 0.656851|0.033165|25.1887 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[046/100] 255.2707 sec(s),[Train]acc|loss|time: 0.643422|0.033501|230.2356 sec(s),[Val]acc|loss|time: 0.665306|0.031393|25.0351 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[047/100] 417.6117 sec(s),[Train]acc|loss|time: 0.645246|0.032839|392.9196 sec(s),[Val]acc|loss|time: 0.616618|0.037983|24.6920 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[048/100] 239.2365 sec(s),[Train]acc|loss|time: 0.646463|0.033005|214.9415 sec(s),[Val]acc|loss|time: 0.665306|0.030830|24.2961 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[049/100] 258.1941 sec(s),[Train]acc|loss|time: 0.650720|0.032061|231.9453 sec(s),[Val]acc|loss|time: 0.635569|0.033494|26.2488 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[050/100] 247.0707 sec(s),[Train]acc|loss|time: 0.647071|0.032285|222.6779 sec(s),[Val]acc|loss|time: 0.665598|0.031180|24.3928 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[051/100] 245.8938 sec(s),[Train]acc|loss|time: 0.655078|0.031871|220.5855 sec(s),[Val]acc|loss|time: 0.662391|0.032254|25.3084 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[052/100] 242.5243 sec(s),[Train]acc|loss|time: 0.655788|0.031486|218.0786 sec(s),[Val]acc|loss|time: 0.639067|0.033599|24.4457 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[053/100] 256.4089 sec(s),[Train]acc|loss|time: 0.661970|0.031360|231.3668 sec(s),[Val]acc|loss|time: 0.666181|0.031762|25.0421 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[054/100] 257.1314 sec(s),[Train]acc|loss|time: 0.669572|0.030630|232.1422 sec(s),[Val]acc|loss|time: 0.652770|0.033096|24.9892 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[055/100] 256.8776 sec(s),[Train]acc|loss|time: 0.666734|0.030611|231.3689 sec(s),[Val]acc|loss|time: 0.677551|0.031002|25.5086 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[056/100] 254.4714 sec(s),[Train]acc|loss|time: 0.667241|0.030864|228.7181 sec(s),[Val]acc|loss|time: 0.632653|0.035563|25.7533 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[057/100] 250.2277 sec(s),[Train]acc|loss|time: 0.678695|0.029566|224.8277 sec(s),[Val]acc|loss|time: 0.623615|0.037216|25.4001 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[058/100] 258.7093 sec(s),[Train]acc|loss|time: 0.685283|0.029736|232.5789 sec(s),[Val]acc|loss|time: 0.672303|0.031230|26.1304 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[059/100] 258.2967 sec(s),[Train]acc|loss|time: 0.681431|0.029595|232.1985 sec(s),[Val]acc|loss|time: 0.689504|0.029936|26.0982 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[060/100] 254.1609 sec(s),[Train]acc|loss|time: 0.686094|0.029527|229.4031 sec(s),[Val]acc|loss|time: 0.684257|0.031098|24.7578 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[061/100] 252.5992 sec(s),[Train]acc|loss|time: 0.682141|0.029227|227.9750 sec(s),[Val]acc|loss|time: 0.669096|0.031192|24.6242 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[062/100] 253.3997 sec(s),[Train]acc|loss|time: 0.686702|0.029079|227.9617 sec(s),[Val]acc|loss|time: 0.684840|0.029969|25.4380 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[063/100] 256.1872 sec(s),[Train]acc|loss|time: 0.692074|0.029001|230.8540 sec(s),[Val]acc|loss|time: 0.632653|0.034599|25.3333 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[064/100] 266.3114 sec(s),[Train]acc|loss|time: 0.684573|0.028585|240.6836 sec(s),[Val]acc|loss|time: 0.646356|0.034148|25.6279 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[065/100] 256.5380 sec(s),[Train]acc|loss|time: 0.696331|0.028426|231.5119 sec(s),[Val]acc|loss|time: 0.672595|0.033185|25.0261 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[066/100] 263.0607 sec(s),[Train]acc|loss|time: 0.690553|0.028451|237.2577 sec(s),[Val]acc|loss|time: 0.676385|0.031278|25.8030 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[067/100] 253.8788 sec(s),[Train]acc|loss|time: 0.691466|0.028311|227.4327 sec(s),[Val]acc|loss|time: 0.685423|0.030398|26.4461 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[068/100] 262.0951 sec(s),[Train]acc|loss|time: 0.707379|0.027271|235.8233 sec(s),[Val]acc|loss|time: 0.656560|0.033060|26.2718 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[069/100] 264.4684 sec(s),[Train]acc|loss|time: 0.700081|0.027720|238.7292 sec(s),[Val]acc|loss|time: 0.659184|0.034646|25.7392 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[070/100] 262.9336 sec(s),[Train]acc|loss|time: 0.700081|0.027501|235.7603 sec(s),[Val]acc|loss|time: 0.680175|0.029723|27.1734 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[071/100] 259.1708 sec(s),[Train]acc|loss|time: 0.708392|0.026981|233.4169 sec(s),[Val]acc|loss|time: 0.646939|0.034371|25.7538 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[072/100] 242.5281 sec(s),[Train]acc|loss|time: 0.712041|0.026395|218.3424 sec(s),[Val]acc|loss|time: 0.692711|0.030002|24.1856 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[073/100] 301.2177 sec(s),[Train]acc|loss|time: 0.713663|0.026306|265.1591 sec(s),[Val]acc|loss|time: 0.677843|0.030138|36.0586 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[074/100] 276.6592 sec(s),[Train]acc|loss|time: 0.716298|0.026267|250.6667 sec(s),[Val]acc|loss|time: 0.686589|0.029544|25.9925 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[075/100] 323.6170 sec(s),[Train]acc|loss|time: 0.718427|0.026314|289.8632 sec(s),[Val]acc|loss|time: 0.693294|0.029266|33.7538 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[076/100] 331.9418 sec(s),[Train]acc|loss|time: 0.723495|0.026157|297.1997 sec(s),[Val]acc|loss|time: 0.688338|0.030008|34.7421 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[077/100] 332.4634 sec(s),[Train]acc|loss|time: 0.719339|0.026024|298.9789 sec(s),[Val]acc|loss|time: 0.676385|0.031197|33.4845 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[078/100] 334.1300 sec(s),[Train]acc|loss|time: 0.726333|0.025368|298.5311 sec(s),[Val]acc|loss|time: 0.653061|0.034449|35.5989 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[079/100] 340.1150 sec(s),[Train]acc|loss|time: 0.729272|0.025185|305.8795 sec(s),[Val]acc|loss|time: 0.681341|0.030728|34.2355 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[080/100] 328.9369 sec(s),[Train]acc|loss|time: 0.724204|0.025716|294.6086 sec(s),[Val]acc|loss|time: 0.691254|0.030076|34.3283 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[081/100] 332.1762 sec(s),[Train]acc|loss|time: 0.733327|0.025603|297.2256 sec(s),[Val]acc|loss|time: 0.693003|0.030078|34.9506 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[082/100] 340.3763 sec(s),[Train]acc|loss|time: 0.725218|0.025297|305.1903 sec(s),[Val]acc|loss|time: 0.677843|0.031743|35.1860 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[083/100] 342.3520 sec(s),[Train]acc|loss|time: 0.728765|0.025197|308.6381 sec(s),[Val]acc|loss|time: 0.688921|0.029570|33.7139 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[084/100] 336.6662 sec(s),[Train]acc|loss|time: 0.743057|0.024144|302.1465 sec(s),[Val]acc|loss|time: 0.683673|0.031162|34.5197 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[085/100] 332.6350 sec(s),[Train]acc|loss|time: 0.734239|0.024785|298.8642 sec(s),[Val]acc|loss|time: 0.717784|0.027922|33.7707 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[086/100] 338.1662 sec(s),[Train]acc|loss|time: 0.738496|0.024427|303.8250 sec(s),[Val]acc|loss|time: 0.708163|0.029238|34.3412 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[087/100] 340.3294 sec(s),[Train]acc|loss|time: 0.739915|0.024090|305.0058 sec(s),[Val]acc|loss|time: 0.694169|0.032824|35.3236 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[088/100] 315.1367 sec(s),[Train]acc|loss|time: 0.741942|0.024070|289.8034 sec(s),[Val]acc|loss|time: 0.708746|0.030258|25.3333 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[089/100] 250.6538 sec(s),[Train]acc|loss|time: 0.745287|0.023766|224.8836 sec(s),[Val]acc|loss|time: 0.692711|0.030621|25.7701 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[090/100] 252.9699 sec(s),[Train]acc|loss|time: 0.745591|0.024162|229.2463 sec(s),[Val]acc|loss|time: 0.695044|0.031636|23.7236 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[091/100] 257.0143 sec(s),[Train]acc|loss|time: 0.748226|0.023349|226.0440 sec(s),[Val]acc|loss|time: 0.694461|0.031241|30.9702 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[092/100] 582.7773 sec(s),[Train]acc|loss|time: 0.749949|0.023533|557.9978 sec(s),[Val]acc|loss|time: 0.700000|0.029503|24.7795 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[093/100] 506.5532 sec(s),[Train]acc|loss|time: 0.751774|0.022973|480.8479 sec(s),[Val]acc|loss|time: 0.711953|0.028859|25.7053 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[094/100] 513.3785 sec(s),[Train]acc|loss|time: 0.756740|0.023351|489.6080 sec(s),[Val]acc|loss|time: 0.683382|0.033024|23.7705 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[095/100] 500.6322 sec(s),[Train]acc|loss|time: 0.758869|0.022634|476.5885 sec(s),[Val]acc|loss|time: 0.717493|0.028781|24.0437 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[096/100] 484.5939 sec(s),[Train]acc|loss|time: 0.765964|0.022405|461.5455 sec(s),[Val]acc|loss|time: 0.686589|0.032174|23.0484 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[097/100] 497.5747 sec(s),[Train]acc|loss|time: 0.754916|0.022863|474.0257 sec(s),[Val]acc|loss|time: 0.681924|0.032779|23.5491 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[098/100] 488.4114 sec(s),[Train]acc|loss|time: 0.757044|0.023017|464.2470 sec(s),[Val]acc|loss|time: 0.684548|0.030627|24.1644 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[099/100] 490.6926 sec(s),[Train]acc|loss|time: 0.757653|0.022538|466.9430 sec(s),[Val]acc|loss|time: 0.697085|0.030254|23.7495 sec(s)\n",
      "training: batch#0\n",
      "training: batch#100\n",
      "training: batch#200\n",
      "training: batch#300\n",
      "[100/100] 486.2723 sec(s),[Train]acc|loss|time: 0.761403|0.022475|462.4440 sec(s),[Val]acc|loss|time: 0.685423|0.031893|23.8283 sec(s)\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(),lr = learning_rate)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode = 'max',factor = 0.5,patience = 20,verbose = True,threshold = 1e-4,threshold_mode = 'rel',cooldown = 0,min_lr = 0,eps = 1e-8)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max = 10,eta_min=0, last_epoch=-1)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size = 400,gamma = 0.5,last_epoch=-1,verbose = False)\n",
    "# scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer,max_lr = 0.01,total_steps = 1550,verbose = True)\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer,base_lr = 3e-4,max_lr = 3e-3,mode = 'exp_range',gamma = 0.98,step_size_up = 10,cycle_momentum = False)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "val_acc_history = []\n",
    "val_loss_history = []\n",
    "train_acc_history = []\n",
    "train_loss_history = []\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    epoch_start_time = time.time()\n",
    "    epoch_train_time = time.time()\n",
    "    val_acc = 0.0\n",
    "    val_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    train_loss = 0.0\n",
    "    model.train()\n",
    "    for batch_id,DATA in enumerate(trn_loader):\n",
    "        optimizer.zero_grad()\n",
    "        train_pred = model(DATA[0].cuda())\n",
    "        batch_loss = loss(train_pred,DATA[1].cuda())\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        # scheduler.step(val_acc)\n",
    "        scheduler.step()\n",
    "        train_acc += np.sum(np.argmax(train_pred.cpu().data.numpy(),axis = 1) == DATA[1].numpy())\n",
    "        train_loss += batch_loss.item()\n",
    "        train_acc_history.append(train_acc)\n",
    "        train_loss_history.append(train_loss)\n",
    "        if batch_id % 100 == 0:\n",
    "            print(f'training: batch#{batch_id}')\n",
    "\n",
    "    epoch_eval_time = time.time()\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i,DATA in enumerate(val_loader):\n",
    "            val_pred = model(DATA[0].cuda())\n",
    "            batch_loss = loss(val_pred,DATA[1].cuda())\n",
    "            val_acc += np.sum(np.argmax(val_pred.cpu().data.numpy(),axis = 1) == DATA[1].numpy())\n",
    "            val_loss += batch_loss.item()\n",
    "            val_acc_history.append(val_acc)\n",
    "            val_loss_history.append(val_loss)\n",
    "            if batch_id % 100 == 0:\n",
    "                print(f'validating: batch{batch_id}')\n",
    "    print('[%03d/%03d] %2.4f sec(s),[Train]acc|loss|time: %3.6f|%3.6f|%2.4f sec(s),[Val]acc|loss|time: %3.6f|%3.6f|%2.4f sec(s)' % (epoch+1,epoch_num,time.time()-epoch_start_time,train_acc/train_set.__len__(),train_loss/train_set.__len__(),epoch_eval_time-epoch_train_time,val_acc/val_set.__len__(),val_loss/val_set.__len__(),time.time()-epoch_eval_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a98cf0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "309"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "len(trn_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "843da6e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x242fd5ae730>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAABALUlEQVR4nO3dd3xUVfr48c/JpJNeCCWUAOmNEgErxQaIXcC6ul+VdV3Utex3/arbdX+6tsVd1rKuu4ursooNV+wQXRtS00MaIYSW3iBlyvn9MZPJgAECKTOZed6v17wy994z9z5n7syTO+eee67SWiOEEGL483J2AEIIIQaGJHQhhHATktCFEMJNSEIXQgg3IQldCCHchLezNhwVFaUnTpzY5/KHDh1ixIgRgxeQi/LEentincEz6+2JdYb+1Xvr1q11Wuvo3pY5LaFPnDiRLVu29Ll8dnY2c+fOHbyAXJQn1tsT6wyeWW9PrDP0r95Kqd3HWiZNLkII4SYkoQshhJuQhC6EEG5CEroQQrgJSehCCOEmJKELIYSbkIQuhBBuwmn90IUQwhPUtdexs2EnDR0NtHS10NzZTFBn0KBsSxK6EEIMkObOZgrrCymoLyC/Lp/8unwOHj74vXLLIpYNyvYloQshxClo6WqhvKmc4oZi8mrzyKvLo7Kl0r58XPA4po+cTmpUKimRKcQExhDiG0KwbzD//eK/gxKTJHQhhDiBmsM1FNQVUNRQRGF9IcUNxUcceUf6R5Ienc4lky8hNSqV1MhUQv1ChzxOSehCCOGgtauV/Lp88uryyK/Lp6CugJr2GgC8lBeTQidx2qjTiA+PZ0rYFOLD4hk1YhRKKSdHLgldCOHBWrpaKGsso6ihiIK6AgrqC9jVvAuN9V7LE0MmMnP0TNKi0kiNTCUhPIFAn0AnR31sktCFEB7hsPEweXV55NTmkFub+71mk6iAKNIi01gYt5CMqAzSotMI8Q1xYsQnTxK6EMLtmC1mdjXvorChkNzaXHJqcyhpLMGiLQDEhcaRNSqL+LB44sPjSQhPICYwxiWaTfpDEroQYtjSWrO3bS+ljaVUNFdQ2VJJRXMFpY2ltJvaAQj0DiQ9Op1b0m9havRUMqIznHLCcihIQhdCuDytNXXtdZQ2llLeXE55k/VR2lTKIeMhe7mogCgmhkzkyvgrSY5MJiUihbjQOAxeBidGP3QkoQshXE6HqYOc2hw2H9jMjpodlDSW0NjZaF8e5hfGpNBJXDzpYhIiEogPi2dy2GSCfYOdGLXzSUIXQjjdvrZ9bK/ZTl5dHnm1eRQ1FGG0GPFSXiSGJzJv/DwSwhNICE9gcthkIvwjnB2yS5KELoQYUu2mdnY27KSwvpBP6j7hkbWPcODQAQACvANIiUzh+pTryYrJYtrIaR5/1H0yJKELIQaNyWKivKncfqFObl0u5U3l9t4mIYYQZsfO5qbUm5g+cjrx4fF4e0laOlV9eueUUguAlYABeFFr/ehRy58G5tkmA4GRWuuwAYxTCDEMtHS1sO3gNjYf2Gzv691h7gAg1C+UtKg0zh1/LikRKSRHJlP0XRHz5s47wVpFX50woSulDMAq4HygGtislFqntS7sLqO1vtuh/B3AtEGIVQjhYjrNnWyv2c43+77h2/3fUlRfhEbj6+VLSmQKVyVcRWpUKulR6YwPHv+9ft7FqthJkbunvhyhzwTKtNYVAEqpNcClQOExyl8D/GpgwhNCuIpOcydlTWUU1xdTUG+9TL6ksQSTxYS38iYjOoPbMm/jtFGnkRGdgZ/Bz9khexyltT5+AaWuAhZorW+xTd8AzNJar+il7ATgWyBWa23uZflyYDlATEzMjDVr1vQ50La2NoKCBmdQeFfmifX2xDqDa9W73dLOnq49VHdVU91Vzd6uvRwwHsCCte07QAUwzm8c433HM8V/ClP8puDndfIJ3JXqPJT6U+958+Zt1Vpn9bZsoM8+XA2s7S2ZA2itXwBeAMjKytJz587t84qzs7M5mfLuwhPr7Yl1BufV22g2srNxJzm1OfabMjiO6z0yYCSJIxO5KOIikiKSSIpIIjY4Fi/V/ztYyr4eWH1J6HuBcQ7TsbZ5vbka+El/gxJCDI6WrhZKG0spaSyhuKGY4oZiShtLMVqMgG2Aqqg0Fk9aTGpUKskRyUQGRDo5atFXfUnom4F4pVQc1kR+NXDt0YWUUklAOPDNgEYohDgltYdr7TdkKKwvZGfDTvYd2mdfHuYXRlJEEtcnX09aVBoZ0RluMUCVK8rZ00TR/hZ21R2iou4QmYEm5g7Cdk6Y0LXWJqXUCuAjrN0WX9JaFyilfgts0VqvsxW9GlijT9QoL4QYcHXtdfbboHXfUae+o96+fGLIRDKjM1mSuMR+xaUk78HXaTLz63WFvPZdFQC+Bi8mRAYSP2ZwttenNnSt9Xpg/VHzfnnU9K8HLiwhxLF0mjspqi8itzbXeql8XR5726ytoAZlYHLYZM4ae5a9vTspIokgX8878ehsB5o7+PErW9le1cRtcyZz3azxjAkLwOClyM7OHpRtyiVZQrgwo9lIeXO5vb3bcZwTgNEjRpMelc41SdeQHpVOcmQyAd4BTo5abKqo5yevbqO9y8yz101nYfroIdmuJHQhXITWmoOHDlLUUERObQ7bDm6joL6ATnMnYB3npLvNOzM6k4zoDKIDo50ctXCkteYfX1fyyPtFjI8MZM3y2UwZOXRj0UhCF8JJDhsPk1uXy/aD29lRu4PcA7m0VbUB4K28SY5MZmniUtKj0kmMSGRC8ASPGdd7ODrcZeKBt/J4Z8c+zk+J4cmlmYT4+wxpDJLQhRgCJouJ0sZScmtzya+39vWuaK7Aoi0oFPHh8aQFpDEvdR5JEUnSdDLM5O9t5s4129lVd4h7z0/gJ/Om4OU19CecJaELMQgOGw9bm01qtrHt4Dby6vLst0QL9wsnNSqV8yacZ78lWrBvsPVik+S5zg1cnBSLRfPilxU8/tFOIkb48srNszhjSpTT4pGELkQ/WbSFyuZKcuty7V0HSxpLMGuz/QYNl025jKnRU8kcmcmYEWOku6AbONjSwb2v5/BlWR0Xpsbw6BUZhI/wdWpMktCFOAndNyUurC+kqKGI/Lp8CuoKaDW2AhDkE0RqVCr/k/Y/TI+ZztToqdJl0A19UniQ/12bQ7vRzO8vT+eameNc4p+0JHQhjqOpo4nixmLy6/LJqckhty6Xho4GwHrickr4FBbELSA9Kp2M6AziQuMGZIwT4ZoOdZp4ZH0Rr26qImV0CM9cM40pI13nH7YkdCGwHnnvP7SfovoiihuLKa4vprix2H5rNLBebXnW2LPIjM4kJTKF+PB4GSLWg2zd3cg9r++gquEwt54dx30XJuLn7Vq9jiShC4902HiYgvoCcmpzyKnNIa82z36pvJfyIi4kjmkjp5EckWztdRKRTJh/mHODFk5htmhWflbKnzeUMjo0gNdunc3sSa45YJkkdOH2jGYjZU1l9psyFNQV2E9agvXI+4wxZ5AenU5qZCrx4fHSZVAA1sv371qznU27Grhi2lh+c2kqwUPct/xkSEIXbsWiLexq3mUf56SwvpCSxhL7pfLBvsGkRqZyc/rNZEZnkhmdSahfqJOjFq5oQ/FB7nsjl/YuM08syeSqGbHODumEJKGLYe2w8TD5dflsr9nO9prt5NTm0Ga0Xm0Z7BNMSmQK1yVfR3JEMmlRaYwLdo3eCMJ1Heo08fD7Rbz2XRVJo4L587XTXerE5/FIQhfDRqe5k9LGUgrrCymoLyC3NveIqy0nh01mYdxCMqMzSY9OZ2LIROlxIk7K1t0N3PN6DlUNh/nROZO454IElzvxeTyS0IXL0Vqzv20/xQ3FlDSWUNZURllTGZXNlZi0CYBQv1DSotI4f8L5pEelkzkykxDfECdHLoarDqOZJz/eyYtf7mJMaABrbp3NLBc98Xk8ktCFU3VfqJNfl09hg/XOOnkH8zhcddheJjYolilhU5g7bi4pkSmkRKbI1ZZiwGyvauTe13OoqDvEtbPG88CiZIL8hmdqHJ5Ri2GrtauVwvpC8uvyyavLY0fNDnt3QR8vH+LD45kaOJX5qfNJjEgkITyBQJ9AJ0ct3JHWmr99uYtHPygmJsSff908i7PinTcOy0DoU0JXSi0AVmK9Bd2LWutHeymzFPg1oIEcrfX37jsqPIvZYmZ3625ya3PZUbOD7TXbqWiusC8fFzyOM8acYW/zjg+Lx8fgYx2kKmmu8wIXbq+1w8j/rs3lg/wDnJ8SwxNLMgkNcN3uiH11woSulDIAq4DzgWpgs1Jqnda60KFMPPB/wJla60al1MjBCli4Jou2UNlSSU6N9UKd4oZiyprK7DdnCPYNZtrIaSyKW0RaVBqpkalyoY5wiu4Tn9WN7TywKIlbz57kNs13fTlCnwmUaa0rAJRSa4BLgUKHMrcCq7TWjQBa65qBDlS4lrr2Omt7d12efYTBlq4WwJq8UyJTWJq4lMTwRFIjU5kUNkl6nAin6jJZ+OOnJTz3eTmjQwNYs3w2p02McHZYA0pprY9fQKmrgAVa61ts0zcAs7TWKxzKvAOUAGdibZb5tdb6w17WtRxYDhATEzNjzZo1fQ60ra2NoKDh0Rd0ILlCvc3aTFVXFeUd5ZR3llPVVUWL2Zq8FYrRPqOZ4DeBOL844vziGOk9sl/J2xXq7AyeWO+hqnPNYQurdnSyu8XC2WO9uTbZlwBv5x2V96fe8+bN26q1zupt2UCdFPUG4oG5QCzwhVIqXWvd5FhIa/0C8AJAVlaWnjt3bp83kJ2dzcmUdxdDXW+zxUxlSyVFDUUU1BWQX5dPcUMxHeYOwHqZ/JzRc0iOTCY5IpmUyJQBP2kp+9pzDEWdPy44wO/eyEHhxfM3TOPC1FGDur2+GKx69yWh7wXGOUzH2uY5qgY2aa2NwC6lVAnWBL95QKIUg6alq4VtB7ex+cBmdtTsoKSxxJ68/Q3+JEcmc1XCVUyPmc60kdOIChjevQCE5zCZLTz+0U6e/6KC9LGh/OW66YyLcO8eU31J6JuBeKVUHNZEfjVwdA+Wd4BrgL8rpaKABKAC4VK6zF2UNZXZ275za3MpbypHo/H18iU9Op0liUtIikgiKSKJSaGT8PaSnq1i+Klp6WDFa9v5blcD180azy8Wp+DvM3yu+DxVJ/y2aq1NSqkVwEdY28df0loXKKV+C2zRWq+zLbtAKVUImIGfaa3rBzNwcXztpnaKG4oprLderFPcUExFU8URV1qmR6VzwcQLyIrJIiM6Q8b2Fm7hm/J67nhtO4c6Tfxx2VQumzbW2SENmT4dfmmt1wPrj5r3S4fnGrjH9hBD7OgRBvPq8ihtLLUPDxvpH0lyZDJzYueQGJFIckSyDFIl3E6XycLTn5bw/OflTIwawau3ziIhJtjZYQ0p+T09zJgsJnY176K4oZiihiJ2NuykoL6AQ8ZDgHWEwbSoNG5Ov5m0yDRSIlMYGThSkrdwazsPtPLTf++gaH8Ly7LG8YuLU4bt5fv94Xk1HkaMFiPVXdW8Xfo2BfUFFDUUUdLQc9LSz+BHfFg8F8VdREZ0howwKDyO1pqXv93Nw+8XEeLvzV9/kMX5KTHODstpJKG7iMPGw+TWWS+RL2sqo7ypnMqWSkwWE+yHET4jSIpIYkniEnt3wQkhE+SkpfBYze1Gfr42lw8LDjA3MZonlmQSFeTZ54EkGzhBl7mL0sZSihqK7Ccui+qLMGkTCsW44HFMCp3EObHnYDlg4cqzrmR8yHg58hbCJre6idtf2caB5g4eWJTELWdNwstLmhUloQ+y7rvJ59TmkFubS25tLkUNRfZbogX5BJEYkchNaTcxfeR0po6cSrBvz4mc7OxsJoZOdFL0QrgWrTX/2lTF794rJDrYj9dvO53p48OdHZbLkIQ+wLrvJm/vcVKbR027dWgbf4M/KZEpXJ98PWlRaSRHJhMbFCsnLIXog6bDXfx6XQHv7NjH3MRonl46lfARvs4Oy6VIQu8Hi7ZQ1VJFXl2e/Qh8Z+NOLNoCWIeHzRqVxdSRU8mMziQhPEHavIU4SR1GM//8upJVG8to6zRx3wUJ3D53ijSx9EKyy0moPVxLbl2ufYyT/Pp8WrtaAQj0DiQ9Op1b0m+xju8dlU64v/wUFOJUaa15L3c/j31QzN6mduYlRvPzhUkkjZJbDR6LJPRjaO5spqSxhKL6IvLr8smpzWHfoX0AGJSB+PB4LphwgbW7YFQ6k0InYfBy/0uLhRgKxQda+NW7BWza1UDa2BCeWJLJ6ZOH3z0+h5okdKwjDFY0V7CjdgfbD25nR+0O9rTusS+PCYwhMzqT65KvIyM6g6SIJPy9/Z0YsRDuqbndyNOflPDyt7sJ9vfm95ens+y0cRikeaVPPC6hd99Zp7urYH5dPkUNRbSb2gGI8I9g2shpXBF/BckRySRGJMoIg0IMMotFs3ZbNY99UEzD4S6unTme+y5IlJOeJ8ntE3pjR6P9pGVObQ75dfn2y+T9DH4kRiRy+ZTLSYtKIzM6U8Y4EWKIfVVWx//7oIj8vS3MmBDOPy+ZSdrYUGeHNSy5TULv7u9d1lRGaWMpJY0l5NXl2ZtODMpAQngCiyctJi3KOsaJDA8rhPPk723myS0d5H24ibFhATy9LJPLpo6VA6p+GJbZTGtNdVs1O2p2kFObY0/gbcY2e5mYwBjSotK4Mv5KMqIzSI1MHfA76wghTo7Wmm/K63n283L+W1pHoDc8uCiZG06f4BHjlQ+2YZfQ3yp9iz9t/xN17XWAdYyTxPBELpp0EQnhCcSHxzM5bDIhvtK1SQhXYbFoPi48yLOfl5Ozp4moID/uX5jE+K4qFp0zydnhuY1hl9CjAqKYNXoW06KnMS1mGlPCpsgYJ0K4KLNF8+6OvazaWEZ57SHGRwTy8GVpXDUjFn8fA9nZe068EtFnwy6hnxN7DufEnuPsMIQQx2GxaD7IP8BTn+ykvPYQyaNDeOaaaSxKG4W3QQ7ABkufErpSagGwEust6F7UWj961PKbgMfpuXn0n7XWLw5gnEKIYUBrzcadNTz5cQkF+1qYMjKIZ6+bzoK0UXKycwicMKErpQzAKuB8oBrYrJRap7UuPKrov7XWK/oTjNFopLq6mo6Oju8tCw0NpaioqD+rH5ZOtd7+/v7Exsbi4+MzCFEJ8X3fVtTz+Ec72bq7kfERgTy1NJNLp46Vi4KGUF+O0GcCZVrrCgCl1BrgUuDohN5v1dXVBAcHM3HixO/9N29tbSU42LPuDwinVm+tNfX19VRXVxMXFzdIkQlhta+pnUfWF/F+7n5Ghfjz+8vTWZIVi480rQw5Zb2/83EKKHUVsEBrfYtt+gZgluPRuK3J5f8BtUAJcLfW+ntnO5RSy4HlADExMTPWrFlzxPLQ0FAmT57c608zs9mMweB53ZpOtd5aa8rLy2lubh6EqAZXW1sbQUFBzg5jyA23eneZNR9VGnmvwojWsHiSDwvjfPA19P2IfLjVeaD0p97z5s3bqrXO6m3ZQJ0UfQ94TWvdqZT6EfBPYP7RhbTWLwAvAGRlZem5c+cesbyoqIiQkN67G8oR+snz9/dn2rRpAxzR4MvOzuboz4YnGC71Nls0b26t5qlPSjjQYuSClBh+sTiFcREnf53HcKnzQBusevcloe8FxjlMx9Jz8hMArXW9w+SLwB/6H5oQwtVsrmzgF+/kU3yglanjwlh59VRmTZJREF1FXxL6ZiBeKRWHNZFfDVzrWEApNVprvd82eQngeWcvhXBjDYe6ePSDIl7fUs3YsAD+ct10FkrPFZdzwoSutTYppVYAH2HttviS1rpAKfVbYIvWeh1wp1LqEsAENAA3DWLMLiMoKIi2trYTFxRimNJa85/c/fxqXQEt7UZumzOZO8+dQqDvsLuExSP0aa9ordcD64+a90uH5/8H/N9ABvab9woo3Ndinx6Ik6IpY0L41cWp/Q1NCI9Q19bJQ2/n82HBATJjQ3ns1llytyAXJ/2KHNx///2sWrXKPv3rX/+ahx9+mHPPPZfp06eTnp7Ou+++26d1tbW1HfN1q1evJiMjg8zMTG644QYADh48yOWXX05mZiaZmZl8/fXXA1s5IU7CB3n7ueDpL9hQXMP/LkjkzR+fIcl8ONBaO+UxY8YMfbTCwsLvzevW0tJyzGUDZdu2bfqcc86xTycnJ+uqqird3Nystda6trZWT548WVssFq211iNGjDjmuoxGY6+vy8/P1/Hx8bq2tlZrrXV9fb3WWuulS5fqp59+Wmuttclk0k1NTVrr/tX7eO+nK9u4caOzQ3AKV6h3c3uXvvvf2/WEn/9HX/TMF3rngcH93rlCnZ2hP/XG2tTda16VhjAH06ZNo6amhn379lFbW0t4eDijRo3i7rvv5osvvsDLy4u9e/dy8OBBRo0addx1aa154IEHvve6DRs2sGTJEqKirHdBioiIAGDDhg2sXr0aAIPBQGioDPAvhtaminrueT2HAy0d3Dl/CnecGy8XBw0zktCPsmTJEtauXcuBAwdYtmwZr7zyCrW1tWzduhUfHx8mTpzY69AERzvV1wkx1IxmC898VsqqjWWMiwjkjdtOZ/r4cGeHJU6B/Ps9yrJly1izZg1r165lyZIlNDc3M3LkSHx8fNi4cSO7d+/u03qO9br58+fzxhtvUF9v7brf0NAAwLnnnsuzzz4LWE8AD8crPMXwU1V/mCXPfcOfNpRx5fRY1t95tiTzYUwS+lFSU1NpbW1l7NixjB49muuuu44tW7aQnp7O6tWrSUpK6tN6jvW61NRUHnzwQebMmUNmZib33HMPACtXrmTjxo2kp6czY8YMCgsHfKgcIey01ry1rZqFK7+gvLaNP187jceXZDLCT360D2ey93qRl5dnfx4VFcU333zTa7nj9UE/3utuvPFGbrzxxiPmxcTE9LkHjRD90XzYyC/X5fPujn3MnBjBU8syiQ2X2zO6A0noQngIi0Xz+pY9/OGjnTS3G7n3/ARunzdFhrd1I5LQ+ykvL8/el7ybn58fmzZtclJEQnxfwb5mHngrj5zqZk6bGM5vLkkjZYz0K3c3ktD7KT09nR07djg7DCF6ZTJbeP6LCv74aQmhAb78cdlULp06RsZgcVOS0IVwUxW1bdz3Rg7bqpq4KH00D1+WRvgIX2eHJQaRJHQh3MyhThN/3ljGi/+twN/HIEflHkQSuhBu5OOCA/xqXQH7mzu4YvpY7l+YxMhgf2eHJYaI9EPvh+PdQqqyspK0tLQhjEZ4svYuMw+8ncfyl7cSFujLmz8+naeWTpVk7mHkCF2IYW7HnibufX0HFXWH+NGcSdx7fiK+3nKs5olcN6F/cD8c6LnAJ8BsAkM/wx2VDgsfPebi+++/n3HjxvGTn/wEsA6f6+3tzcaNG2lsbMRoNPLwww9z6aWXntRmOzo6+PGPf8yWLVvw9vbmqaeeYt68eRQUFPDDH/6Qrq4uLBYLb775JmPGjGHp0qVUV1djNpu57777uOmmm/pTa+Gmduxp4pnPStlQXENMiB//unkWZ06JcnZYwolcN6E7wbJly/jpT39qT+ivv/46H330EXfeeSchISHU1dUxe/ZsLrnkkpM6wbRq1SqUUuTl5VFcXMwFF1xASUkJzz33HHfddRfXXXcdXV1dmM1m1q9fz5gxY3j//fcBqK6uHpS6iuGrsu4QD79fyKdFNYQF+vCzCxP5wekTCPb3cXZowsn6lNCVUguAlVhvQfei1rrXw1yl1JXAWuA0rfWWfkV21JF0e2srwcHB/VrliQzk8LmOvvzyS+644w4AkpKSmDBhAiUlJZx++uk88sgjVFdXc8UVVxAfH096ejr33nsvP//5z1m8eDFTp04dpNqK4eZwl4m/bCznhS8q8PX24mcXJnLjGRMJkvFXhM0JPwlKKQOwCjgfqAY2K6XWaa0LjyoXDNwFDOtLJAdq+Ny+uPbaa5k1axbvv/8+ixYt4vnnn2f+/Pls27aN9evX89BDD3HWWWfxyCOPDMj2xPDUcKiLV77dzT+/2U1dWydXTLP1XgmRE57iSH351z4TKNNaVwAopdYAlwJHDwf4O+Ax4GcDGuEQW7ZsGbfeeit1dXV8/vnnvP7666c0fK6js88+m1deeYX58+dTUlJCVVUViYmJVFRUMGnSJO68806qqqrIzc0lKSmJiIgIrr/+esLCwnjuuecGoZZiOCja38Lqbyp5a9teOk0W5iZGs2LeFLImRjg7NOGi+pLQxwJ7HKargVmOBZRS04FxWuv3lVLHTOhKqeXAcrCOLpidnX3E8tDQUFpbW3t9rdlsPuaygTR+/Hiam5sZNWoUQUFBXHrppSxdupTU1FSmTZtGQkICbW1t9liOFVNbWxsWi4XW1lZuuOEG7r77blJTU/H29uYvf/kLXV1dvPzyy6xZswYfHx9GjhzJHXfcwaZNm/jFL36Bl5cX3t7ePPnkk6dc746Oju+9x8NBW1vbsIy7v9ra2tiwcSNbD5r5ZLeRkkYLPl5w+hhvLpzox9igw7RV5pJd6exIB44n7+vBqLey3qLuOAWUugpYoLW+xTZ9AzBLa73CNu0FbABu0lpXKqWygftO1IaelZWlt2w5skhRURHJycm9lm8dgjZ0V9Sfeh/v/XRl2dnZzJ0719lhDCmtNX984zM+2udL8YFWxkcEcv3s8SzNGkdYoPteru+J+xr6V2+l1FatdVZvy/pyhL4XGOcwHWub1y0YSAOybT0/RgHrlFKX9PvEqBBuzmLRfFp0kFXZ5eTs6SQuypuVV09lccYYGdZWnLS+JPTNQLxSKg5rIr8auLZ7oda6GbB3fu3rEbq7kOFzxanoMJp5L2cfz39RQVlNG+MiAvhhqi8PXnsO3nJjZnGKTpjQtdYmpdQK4COs3RZf0loXKKV+C2zRWq8b7CBdmQyfK05GycFWXt1Uxdvb99LcbiRpVDArr57KRemj+fK/X0gyF/3Spw6sWuv1wPqj5v3yGGXn9j8sIdyH0Wzh44KD/PObSr7b1YCPQXFh6iiumTmeMyZHyiiIYsDIFQlCDJJOk5lXN1Xx3OflHGzpZFxEAP+3MImrZsQSGeTn7PCEG5KELsQAM5otrN1azZ8+K2Vfcwez4iL4/eXpzE0cKSc6xaCShC7EAGnvMrNmcxV//aKCfc0dTB0XxuNLMqVZRQwZOQPjoKmpib/85S8n/bpFixbR1NQ08AGJYaHDaOaFL8o587EN/Oa9QmLDA/n7Tafx9u1ncOaUKEnmYsjIEbqD7oR+++23HzHfZDLh7X3st2r9+vXHXCbcl9mieWf7Xp76pIS9Te3MSYjmjvlyab5wHpdN6I999xjFDcX2abPZjMFg6Nc6kyKS+PnMnx9z+f333095eTlTp07Fx8cHf39/wsPDKS4upqSkhMsuu4w9e/bQ0dHBXXfdxfLlywGYOHEiW7Zsoa2tjYULF3LWWWfx9ddfM3bsWN59910CAgJ63d5f//pXXnjhBbq6upgyZQovv/wygYGBHDx4kNtuu42KigosFgvPP/88Z5xxBqtXr+aJJ55AKUVGRgYvv/xyv94PcWq6TBbe2b6X574op6L2EBmxoTy+JIMzJstY5MK5XDahO8Ojjz5Kfn4+O3bsIDs7m4suuoj8/Hzi4uIAeOmll4iIiKC9vZ3TTjuNK6+8ksjIyCPWUVpaymuvvcZf//pXli5dyptvvsn111/f6/auuOIKbr31VgAeeugh/va3v3HHHXdw5513MmfOHN5++22amppQSlFQUMDDDz/M119/TVRUFA0NDYP7ZojvOdRp4rXvqnjxv7s40NJB6pgQVl07nYVpo/CSk53CBbhsQj/6SNoZY7nMnDnTnswBnnnmGd5++20A9uzZQ2lp6fcSelxcnH0M8xkzZlBZWXnM9efn5/PQQw/R1NREW1sbF154IQAbNmxg9erVABgMBoKDg1m9ejVLliwhKsp6FBgRIT/rh0rDoS7+8XUl//y6kuZ2I7PiInjsqgzOiZf2ceFaXDahu4IRI0bYn2dnZ/Ppp5/yzTffEBgYyNy5c3sdF93Pr6d/scFgoL29/Zjrv+mmm3jnnXfIzMzkH//4h0eOOufKympa+duXlby1rZpOk4ULUmK4be5kpo8Pd3ZoQvRKerk4CA4OPuZQtc3NzYSHhxMYGEhxcTHffvttv7fX2trK6NGjMRqNvPLKK/b55557Ls8++yxgPXfQ3NzM/PnzeeONN6ivrweQJpdB1HzYyB2vbee8p77gzW3VXDF9LJ/ecw4v/CBLkrlwaXKE7iAyMpIzzzyTtLQ0AgICiImJsS9bsGABzz33HMnJySQmJjJ79ux+b+93v/sds2bNIjo6mlmzZtn/maxcuZLly5fzt7/9DaUUzz//PKeffjoPPvggc+bMwWAwMG3aNP7xj3/0OwZxpG8r6rn73zuobe1kxbwp/PDMiXJVpxg2Tjge+mCR8dD7RsZDHxrtXWZWflbK81+UMzFyBCuvnkpGbNiQxuCJY4N7Yp3BueOhC+HWNhbX8Mt1+expaGdZ1jh+eXEKI+TGy2IYkk/tEPjJT37CV199dcS8u+66ix/+8IdOikgANLcbefDtPP6Tu5/J0SN47dbZnD458sQvFMJFSUIfAqtWrXJ2COIo26saueO17Rxo7uDe8xP40ZzJ+HpLHwExvElCFx7FYtH87ctdPPZhMTEh/rxx2+lMk54rwk1IQhceo+FQF/e9kcOG4hoWpI7isSszCA30cXZYQgyYPv3GVEotUErtVEqVKaXu72X5bUqpPKXUDqXUl0qplIEPVYhT992uBhat/C9fltbx20tTefb66ZLMhds54RG6UsoArALOB6qBzUqpdVrrQodir2qtn7OVvwR4ClgwCPEKcVK6TBZWflbCs9nljI8I5K3bzyBtbKizwxJiUPTlCH0mUKa1rtBadwFrgEsdC2itWxwmRwDO6dzeT0M9HvpNN93E2rVrT/p1om9KDrZy+V++YtXGcq6aEct/7jxbkrlwa31J6GOBPQ7T1bZ5R1BK/UQpVQ78AbhzYMIbWsdK6CaT6bivW79+PWFhYYMUlThZHUYzf/y0hMXPfMmB5g5euGEGf7gqkyDpWy7c3IB9wrXWq4BVSqlrgYeAG48uo5RaDiwHiImJ+d5gVKGhofbL35uefIqukhLHDVDTz5HtfBMSCLv3nmMuv/feeykvLycjIwNvb2/8/f0JCwujpKSE7du3c80117B37146Ojr48Y9/bO9HnpaWxueff05bWxtXXnklp59+Ops2bWL06NGsWbPmmOOhG41G2tvbaW1tJTs7m4ceegiTycT06dN5+umn8fPz4xe/+AUffvgh3t7ezJ8/n0ceeYS3336bRx99FIPBQEhICB9++GGv6+/o6BiWA361tbWdctwFdWZWF3Zy8LBm9mgD1yZ541tbTHZ28Ylf7GT9qfdw5Yl1hsGrd18S+l5gnMN0rG3esawBnu1tgdb6BeAFsF76f/Slr0VFRfbL3A/5+mBxuKGFyWzGu583uPDx9TnuZfRPPvkkO3fuJDc3t9fx0FevXn3EeOjXXXcdkZHW+0UGBQUBUF5ezr///W+mTp3K0qVL+fjjj485HrqPjw8BAQH4+Phw++2389lnn5GQkMAPfvAD/vWvf3HDDTfw/vvvU1JSglKKpqYmgoODefzxx/nkk08YO3asfV5v/P39mTZtWr/eM2c4lcuiD3WaePj9Il7bUsXEyEBeviaNs+OjByfAQeKJl8F7Yp1h8Ordl4S+GYhXSsVhTeRXA9c6FlBKxWutS22TFwGl9NOoBx44Ytodx0PvtnPnTuLi4khISADgxhtvZNWqVaxYsQJ/f39uvvlmFi9ezOLFiwE488wzuemmm1i6dClXXHHFANR0eNu6u4F7Xs+hquEwPzpnEnefn4C/T//++QsxHJ0woWutTUqpFcBHgAF4SWtdoJT6LbBFa70OWKGUOg8wAo300twyHA32eOgn4u3tzcaNG/nuu+9Yu3Ytf/7zn9mwYQPPPfccmzZt4v3332fGjBls3br1e/9YPEFrh5GnPinhn19XMjo0gDW3zmbWJM97H4To1qc2dK31emD9UfN+6fD8rgGOyymGejz0bomJiVRWVlJWVma/t+icOXNoa2ujpaWFRYsWceaZZzJp0iTA2qwza9YsZs2axQcffMCePXs8KqFrrfkw/wC/fq+AmtZOrp05nvsXJhHsL/3KhWeT0/4Ohno89G7+/v78/e9/Z8mSJZhMJk477TRuu+02GhoaWLJkCUajEa01Tz31FAA/+9nPKC0tRWvNueeeS2Zm5oDF4upqWjt46O18Pi48SMroEJ67foZcui+EjST0o7z66qu9zvfz8+ODDz7odVl3O3lUVBT5+fn2+ffdd99xt+V4g4pzzz2X7du3H7F89OjRZGdnf+/cwVtvvXXc9bojrTXrcvbxq3UFHO4yc//CJG45Kw5vgwyoJUQ3SejC5dW2dvLQO3l8VHCQaePDePyqTKaMDHJ2WEK4HEnoQ0DGQz81Rx+V/9/CJG45exIGr/5djyCEu3K5hK61RvXzAiJX44zx0J11a8H+ajjUxX+rjbz3eg6bdtVT3djO1HFhPLEkgykjPe8WhEKcDJdK6P7+/tTX19sv1hGnRmtNfX09/v7+zg6lz8pq2njpq128ubWaTpOFiBE1zJwYwYp5U7hqRqy0lQvRBy6V0GNjY6murqa2tvZ7yzo6OoZVghoop1pvf39/YmNjByGigaO15pvyel78chcbimvw9fbiyuljSfKu5YbF8/GSphUhTopLJXQfH58jrsx0lJ2dPSwvY+8vd6x3h9HMezn7eOmrSor2txAV5MtPz4vn+tkTiAryIzs7W5K5EKfApRK6cG97m9pZ/U0l/968h6bDRhJigvjDlRlcMnWMXKovxACQhC4GXeOhLv68sYyXv9mNWWsuSInhB6dPZPakCDlXIsQAkoQuBk1l3SHe3r6Xl77axaFOE1fNiOWu8xIYG9b7cMJCiP6RhC4G1IHmDv6Tu4/3cvaRU90MwLlJI/nfBUkkjpJuh0IMJknoot/q2zr5IP8A63L2sbmyAa0hbWwIDyxKYnHGGMbIEbkQQ0ISujglzYeNfFJ0kPdy9vFlWR1mi2bKyCDuPi+BxRmjmRQtl+YLMdQkoYs+az5s5P28/XyQv59vyusxWTSx4QEsP2cSF2eMIXl0sJzkFMKJJKGL47JYNNklNazdWs2nhTV0mS1MjAzklrMnsSBtFJmxoZLEhXARktBFr8wWzft5+/nTZ6WU1rQROcKX62aP58rpsaSOCZEkLoQL6lNCV0otAFZivQXdi1rrR49afg9wC2ACaoH/0VrvHuBYxRAwmi28u2Mfz2aXUV57iPiRQay8eiqL0kfjI+OpCOHSTpjQlVIGYBVwPlANbFZKrdNaFzoU2w5kaa0PK6V+DPwBWDYYAYvBcajTxOtb9vDXLyrY19xB0qhgVl07nYVpo+QyfCGGib4coc8EyrTWFQBKqTXApYA9oWutNzqU/xa4fiCDFINnf3M7//x6N69u2k1Lh4mZEyN45PJ05iZGS7OKEMNMXxL6WGCPw3Q1MOs45W8Ger9Xm3AZJQdbee7zctbt2IdFaxakjeLmsyYxY4Lcn1OI4Uqd6EYISqmrgAVa61ts0zcAs7TWK3opez2wApijte7sZflyYDlATEzMjDVr1vQ50La2NoKCPK9v80DXu6rFzNtlRrbXmPE1wJxYby6Y4EN0oOu0j8u+9hyeWGfoX73nzZu3VWud1duyvhyh7wXGOUzH2uYdQSl1HvAgx0jmAFrrF4AXALKysvTcuXP7sHmr7OxsTqa8uxioejcfNvLkJzv517e7Cfb34c5zJ3HTGROJGOHb/yAHmOxrz+GJdYbBq3dfEvpmIF4pFYc1kV8NXOtYQCk1DXge65F8zYBHKU5Zl8nCvzdX8fSnpTQd7uKG2RO45/xEQgN9nB2aEGKAnTCha61NSqkVwEdYuy2+pLUuUEr9FtiitV4HPA4EAW/YTqRVaa0vGcS4xQmYzBbe3r6XlZ+VUt3Yzsy4CH59cSopY0KcHZoQYpD0qR+61no9sP6oeb90eH7eAMclTlFbp4k3tuzh719VUtVwmPSxoTxyeTrnxEdJrxUh3JxcKeom6ts6efHLXfzr2920dpjImhDOgxclc0FKjCRyITyEJPRhrra1k7/+t4KXv9lNh8nMorTR3HJ2HNPGS/dDITyNJPRhqulwF89/UcE/vqqk02TmkswxrJgfz5SRntcFTAhhJQl9mNnX1M6a76r4+1eVtHWZuDhjDHedF89kGX9cCI8nCX0YMFs0G4trePW7KrJ31mDRcH5KDPdekEDSKOm1IoSwkoTuwhoOdfF+RRcPfruRvU3tjAz248dzJ7MsazzjIwOdHZ4QwsVIQndB7V1mnv+inOc/r6DdaOb0SSH8YnEy5yXH4C1D2AohjkESuguxWDTv5uzlDx/uZH9zBxelj+aMkCauu3i2s0MTQgwDktBdgNaaTwoP8tQnJRQfaCV9bCgrr57GzLgIsrOznR2eEGKYkITuRFprviyr44mPS8jZ00Rc1AhWXj2VizPGyE0lhBAnTRK6k2ypbODxj3ayaVcDY8MCeOzKdK6cHitt5EKIUyYJfYjlVTfzxMc7+bykluhgP35zSSpXzxyHn7fB2aEJIYY5SehDpGBfM3/6rIwPCw4QFujD/QuTuPH0iQT4SiIXQgwMSeiDyGzRbK5s4Nnscj4vqSXIz5u7zo3n5rPjCPGX8ciFEANLEvoA0Fqzv7mDbVWNbNvdRNH+FqqbDrO/qQOTRRMV5MvPLkzk+tkTCA2QRC6EGByS0E9BS4eR9bn7+W5XAxV1h9hVd4jmdiMAft5eJI8OYdq4cC7OCGDKyCAWpY/G30eaVoQQg0sSeh8ZzRa+LKvj7W17+ajgAJ0mCzEhfkwZGcTijNHEjwxi2vhwkkeH4OstPVWEEENPEvoJ5FY3sWbzHj7I20/jYSOhAT4szRrHVTNiyYgNlZtHCCFcRp8SulJqAbAS6z1FX9RaP3rU8nOAPwIZwNVa67UDHOeQ29vUzh8+LObdHfsI8DFwfkoMl2SO4eyEKOliKIRwSSdM6EopA7AKOB+oBjYrpdZprQsdilUBNwH3DUaQQ6mt08Tzn5fzwhcVANwxfwo/mjOZID/5MSOEcG19yVIzgTKtdQWAUmoNcClgT+ha60rbMssgxDgkukwWXvuuimc+K6X+UBcXZ47h5wsSiQ2XYWqFEMOD0lofv4BSVwELtNa32KZvAGZprVf0UvYfwH+O1eSilFoOLAeIiYmZsWbNmj4H2tbWRlDQwN+VR2vN5oNm3izp4uBhTVKEF0sTfZkU6hrNKoNVb1fmiXUGz6y3J9YZ+lfvefPmbdVaZ/W2bEjbEbTWLwAvAGRlZem5c+f2+bXZ2dmcTPm+2FRRz+8/KCZnTxOJMcE8ujSJuYnRLnWiczDq7eo8sc7gmfX2xDrD4NW7Lwl9LzDOYTrWNm/Yqm3t5Pfri3h7+15Ghfjzh6syuHJ6LAYZ4VAIMYz1JaFvBuKVUnFYE/nVwLWDGtUgMVs0azZX8dgHxbQbzdwxfwq3z50i46kIIdzCCRO61tqklFoBfIS12+JLWusCpdRvgS1a63VKqdOAt4Fw4GKl1G+01qmDGvlJ0FqzobiGxz4spuRgG7MnRfDwZelMGel5bXdCCPfVpzZ0rfV6YP1R837p8Hwz1qYYl1N6sJWH3sln064G4qJG8Ox101mQNsql2smFEGIguG3n6k6TmWezy1m1sYwgP29+d1kaV582Dh+5gYQQwk25ZULfVtXIz9fmUlrTxqVTx/DLxSlEBvk5OywhhBhUbpXQ2zpNPPHRTv75TSWjQ/x56aYs5ifFODssIYQYEm6R0E1mC+/s2MfTn5Swr7mdH8yewM8WJMnl+kIIjzKsM16XycI7O/ayamMZu+sPkzI6hGeumcqMCRHODk0IIYbcsEzoB5o7ePW7Kl7dVEVdWyepY0J44YYZnJ8SI71XhBAea9gl9Je+3MUj64uwaM28xJH84PQJzElwrcv1hRDCGYZdQs8cF8bNZ8Vx/awJjI+UkRCFEKLbsEvoMyaEM2NCuLPDEEIIlyNX2QghhJsYdkfoQggPpTVYTKAtPdPa4vAwO8zTgO7lrwUsZtt6HJZps3W+Njusj57XdK+ze7m9rLY9d4ijJ+BjVsW/vX1Q3iJJ6EJ4Mt1LQnP8e8RzE5iNYDGCqdP6MHda5x0xvwOMHWDuss6zmKzzje1gPGz9ayuTUbsPKgKt88xdPesxm2zrts0zd1nX4yYi4m/DOnDtwJKELsRgs5htya/L+jC225Jae0+yMncRUb8NitqsCc3YDl2HepJfd6I02xKkxZZEuxOrxXhk8rWvt2f99m2bOqwPPZR3jFTgEwg+AdaHtz/4+GMwd4FXCASNBIMvGHzAy8f61+DbM6/7uZc3dPdoUwqUAZRXz3Mvg3VbjmXs08pa1svbWk559SxTXrZ53evz6nmNl2M5Q89ru8t6eR0ZBw497o7R+64mt5yEQXiXJaEL12Tqgq426xGdxdTzs7b7uX2euednuH26u5zpqJ/Qvf0E7+3o1PYz29xlO5Jsd0ionT1Hm45HouZOa8z25NveM63N9mrZ7/jYvXkAbf3Sp2owbwWtVc+v9e4yeIHBD618bAnFMfH5ob0MQE+i0V7eoEaAl8H6GuUNPj7g74v2siVIrRzi8bKGoRXghcaWxFDWeJSyrh8vtPKyrk8Z0MoxCdqee3lbt6EMPevAy+HXgPX91RZNeVUpk0Pi0EZbRS0WQKMt3fsLh/IWMFvsr8VsQutOsFibPbqXa22xzXMo67hdre3Ltbat02JB2z8PHPlai2257l6n7tmG2Wyd39uy7mls2+t+s7XG+4IL4PxLBvpb4xkJXTt+kOxvuuOOAuhZZl9uK6Mt3W12DuUcX+dYtvsD4bA+bdH2aW2x7Wzt8CE5VlxmC775+bRCz2u0PmId9ucOcXzvA3x0eU3PF8Dxg8Yx1t29HrPZ9rO6+8jQiDZ1HwUa0SZjT7I1dVmXGTutXzyLw094s8m2fTOYe5Kpdf0WJptN7LF/+JU991rfV4ck1P322/cN9uR45LwjEycOy/TR6z3maxQa1bP+7vmOb599WoEOBB0AhDmsbKCZbY+OwVj5kAgGavpSUNmOlL28UN1/lQKDwfocrM8NXijlBQaDdXn365SyHWR72ae712Nfl8PDvszhuVIKvJR1HUr1bMteFlsZg62cwxG+ffvWz405NGRQ3s9hl9AbXnmFulV/OfI/5rGed/8dxsKBamcHYaftvybtvySVdZ6Co35p2soq2wfb9tz6BXH8matQqvuI0/pT12g24evvb/tpfNQX2Kvn57Dq/sI5zFfd6zV42behvHqe98Rk3Ta2L6DqXq/B4FDeAD6+Dts29Lzeqzt5KHp+8iuUweHnuup5o+xf7u6k0L0N2zqVUpTvqmRKQrw9IfTUzSFBOGzLniCUOqJ+jq+xxmQ4MlHZYlEGr573rfu543xssdpe3/O+qJ790v3eW2tpW/WRifR7iRWs6/Ty4ssvv+Tsc845cr1HJVf7OtxISXb2oKx32CV034kTCb7wgt7/03Z/obq/ON3/Qe0fFocvRfd/VMf2MS+HD5/DF95eBhy+tA5fUAWYu1Bm289yk/Xkj+o6BCZbk4G2tnsqbXtuNqIsRtDWNlFlsZ30MXeBNtvLdXUews+gbSeFuqzz6dm09bnuDs2+rFtPYnVIusoL5RcIvgHg7Qc+ASjbX3z8wdc27RtonfYJQPkGgHeAfRqfEbbntr/dy7xt6/QdAX7B1iaBk+SpNw7Oy84mwsPqrf398QqUCwQHSp8SulJqAbASayPai1rrR49a7gesBmYA9cAyrXXlwIZqFXTmmQSdeWbvC+0nnzqPOinUfea8+9F9ht7xhJGx52SRqd2hnbSz58y88TB02R7GQ9DZBh3N1odDO+kxKa+ehOfjZ/3r7W9tz/T2B+8g67zukz8GH5rrmgiLnWg/iXRkeV8wOKzHx9863X3SyeALBu+eE0retmR8CklWCOH6TpjQlVIGYBVwPtZf/5uVUuu01oUOxW4GGrXWU5RSVwOPAcsGI2C2rYavVlpPRnWfgOpOygPdUGnwtR15dj9sZ+l9AyEg3HoUGhAG/mHWo1H/EPCzPQIjrGX8w3oSreHkfxDtzM5mtIcdtQkhTk1fMsxMoExrXQGglFoDXAo4JvRLgV/bnq8F/qyUUlrrgT8VFBgFo9IdfuL793Rr8vLpOWq1d3U6uhuUQxcoe1nbkay3bX3dR7xehgEPXwghBos6Uc5VSl0FLNBa32KbvgGYpbVe4VAm31am2jZdbitTd9S6lgPLAWJiYmasWbOmz4G2tbURFBTU5/LuwhPr7Yl1Bs+styfWGfpX73nz5m3VWmf1tmxIT4pqrV8AXgDIysrSJ3Piy1NPlHlivT2xzuCZ9fbEOsPg1bsvg3PtBcY5TMfa5vVaRinlDYRiPTkqhBBiiPQloW8G4pVScUopX6wDEKw7qsw64Ebb86uADYPSfi6EEOKYTtjkorU2KaVWAB9h7bb4kta6QCn1W2CL1nod8DfgZaVUGdDAYIw6I4QQ4rj61IautV4PrD9q3i8dnncASwY2NCGEECdDbnAhhBBuQhK6EEK4CUnoQgjhJk54YdGgbVipWmD3SbwkCqg7YSn344n19sQ6g2fW2xPrDP2r9wStdXRvC5yW0E+WUmrLsa6OcmeeWG9PrDN4Zr09sc4wePWWJhchhHATktCFEMJNDKeE/oKzA3AST6y3J9YZPLPenlhnGKR6D5s2dCGEEMc3nI7QhRBCHIckdCGEcBPDIqErpRYopXYqpcqUUvc7O57BoJQap5TaqJQqVEoVKKXuss2PUEp9opQqtf0Nd3asA00pZVBKbVdK/cc2HaeU2mTb3/+2jfLpVpRSYUqptUqpYqVUkVLqdA/Z13fbPt/5SqnXlFL+7ra/lVIvKaVqbDf+6Z7X675VVs/Y6p6rlJren227fEJ3uKfpQiAFuEYpleLcqAaFCbhXa50CzAZ+Yqvn/cBnWut44DPbtLu5CyhymH4MeFprPQVoxHrPWnezEvhQa50EZGKtv1vva6XUWOBOIEtrnYZ19NbuexC70/7+B7DgqHnH2rcLgXjbYznwbH827PIJHYd7mmqtu4Due5q6Fa31fq31NtvzVqxf8LFY6/pPW7F/Apc5JcBBopSKBS4CXrRNK2A+1nvTgnvWORQ4B+uw02itu7TWTbj5vrbxBgJsN8IJBPbjZvtba/0F1mHEHR1r314KrNZW3wJhSqnRp7rt4ZDQxwJ7HKarbfPcllJqIjAN2ATEaK332xYdAGKcFdcg+SPwv4DFNh0JNGmtTbZpd9zfcUAt8HdbU9OLSqkRuPm+1lrvBZ4AqrAm8mZgK+6/v+HY+3ZA89twSOgeRSkVBLwJ/FRr3eK4zHYXKLfpZ6qUWgzUaK23OjuWIeYNTAee1VpPAw5xVPOKu+1rAFu78aVY/6GNAUbw/aYJtzeY+3Y4JPS+3NPULSilfLAm81e01m/ZZh/s/glm+1vjrPgGwZnAJUqpSqxNafOxti2H2X6Sg3vu72qgWmu9yTa9FmuCd+d9DXAesEtrXau1NgJvYf0MuPv+hmPv2wHNb8MhofflnqbDnq3t+G9Akdb6KYdFjvdrvRF4d6hjGyxa6//TWsdqrSdi3a8btNbXARux3psW3KzOAFrrA8AepVSibda5QCFuvK9tqoDZSqlA2+e9u95uvb9tjrVv1wE/sPV2mQ00OzTNnDyttcs/gEVACVAOPOjseAapjmdh/RmWC+ywPRZhbVP+DCgFPgUinB3rINV/LvAf2/NJwHdAGfAG4Ofs+AahvlOBLbb9/Q4Q7gn7GvgNUAzkAy8Dfu62v4HXsJ4jMGL9NXbzsfYtoLD24isH8rD2ADrlbcul/0II4SaGQ5OLEEKIPpCELoQQbkISuhBCuAlJ6EII4SYkoQshhJuQhC6EEG5CEroQQriJ/w9zbOxmHsE3wQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig,ax = plt.subplots()\n",
    "x = np.linspace(1,epoch_num,epoch_num)\n",
    "x = x.transpose()\n",
    "val_acc_history = np.array(val_acc_history) / val_set.__len__()\n",
    "val_loss_history = np.array(val_loss_history) / val_set.__len__()\n",
    "train_acc_history = np.array(train_acc_history) / train_set.__len__()\n",
    "train_loss_history = np.array(train_loss_history) / train_set.__len__()\n",
    "ax.plot(x,val_acc_history[-epoch_num:],label = 'val_acc')\n",
    "ax.plot(x,val_loss_history[-epoch_num:],label = 'val_loss')\n",
    "ax.plot(x,train_acc_history[-epoch_num:],label = 'train_acc')\n",
    "ax.plot(x,train_loss_history[-epoch_num:],label = 'train_loss')\n",
    "ax.grid()\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8e217d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch] *",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
